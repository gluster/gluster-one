# Gluster Colonizer OEMID file for
# HPE Apollo Gen9 in disperse configuration
# for media repository

flavor:
    name: Digital Media Repository
    g1_path: /usr/share/gluster-colonizer/
    node:
        name: HPE Apollo Gen9
        needs_bootstrap: true
        flavor_path: flavors/hpe-apollo-gen9/   #relative to g1_path
        flavor_module_file_name: hpe-apollo-gen9-dm-repo  #without the .py suffix
        customization_file_name: customize-hpe-apollo-gen9-dm-repo.yml
        verify_file_name: verify-hpe-apollo-gen9-dm-repo.yml
        mgmt_interface: eno1
        storage_interface: bond0
        backend_devices:
          - /dev/sdb
          - /dev/sdc
          - /dev/sdd
          - /dev/sde
          - /dev/sdf
          - /dev/sdg
          - /dev/sdh
          - /dev/sdi
          - /dev/sdj
          - /dev/sdk
          - /dev/sdl
          - /dev/sdm
          - /dev/sdn
          - /dev/sdo
          - /dev/sdp
          - /dev/sdq
          - /dev/sdr
          - /dev/sds
          - /dev/sdt
          - /dev/sdu
          - /dev/sdv
          - /dev/sdw
          - /dev/sdx
          - /dev/sdy
        cache_devices:
          - /dev/nvme0n1
        disktype: JBOD         #JBOD|RAID
        diskcount: 1          #Number of data disks; for 12 disk RAID 6 this is 10; for {J,RAID}BOD it is 1
        dalign: 256            #<integer in KB>
        tuned: rhgs-sequential-io   #tuned profile name
        gluster_vol_set:
            server.event-threads: 4
            client.event-threads: 4
        gluster_vol_set_smb:
            server.allow-insecure: on
            performance.cache-samba-metadata: on
            storage.batch-fsync-delay-usec: 0
            performance.readdir-ahead: on
            performance.parallel-readdir: on
            group: nl-cache
    volname: gluster1
    voltype: disperse          #replica|disperse
    #Arbiter size should be roughly <brick_size>/1024 for the NAS flavor
    arbiter_size: None         #<integer in GB>|None
